import{_ as t,o as a,c as n,a3 as i}from"./chunks/framework.CL3B3Tmm.js";const p=JSON.parse('{"title":"Semantic Code Search","description":"","frontmatter":{},"headers":[],"relativePath":"search.md","filePath":"search.md","lastUpdated":null}'),o={name:"search.md"};function l(d,e,r,s,c,h){return a(),n("div",null,[...e[0]||(e[0]=[i(`<h1 id="Semantic-Code-Search" tabindex="-1">Semantic Code Search <a class="header-anchor" href="#Semantic-Code-Search" aria-label="Permalink to &quot;Semantic Code Search {#Semantic-Code-Search}&quot;">​</a></h1><p>Kaimon provides natural language search over Julia codebases using vector embeddings. Instead of matching exact keywords, you can describe what you are looking for in plain language — for example, &quot;function that handles HTTP routing&quot; or &quot;struct for database configuration&quot; — and Kaimon returns the most semantically relevant code snippets.</p><p><img src="https://github.com/kahliburke/Kaimon.jl/releases/download/docs-assets/kaimon_search.gif" alt=""></p><h2 id="How-It-Works" tabindex="-1">How It Works <a class="header-anchor" href="#How-It-Works" aria-label="Permalink to &quot;How It Works {#How-It-Works}&quot;">​</a></h2><ol><li><p>Source files are split into <strong>chunks</strong> (function definitions, struct definitions, and sliding text windows).</p></li><li><p>Each chunk is converted into a vector embedding using a local Ollama model.</p></li><li><p>Embeddings are stored in a Qdrant vector database.</p></li><li><p>When you search, your query is embedded and compared against stored vectors to find the closest matches.</p></li></ol><p>All processing happens locally — no code leaves your machine.</p><h2 id="requirements" tabindex="-1">Requirements <a class="header-anchor" href="#requirements" aria-label="Permalink to &quot;Requirements&quot;">​</a></h2><p>Semantic search requires two external services running locally:</p><ul><li><p><strong>Qdrant</strong> — a vector database that stores and searches embeddings.</p></li><li><p><strong>Ollama</strong> — a local model runner that generates embeddings from text.</p></li></ul><h3 id="Setting-Up-Qdrant" tabindex="-1">Setting Up Qdrant <a class="header-anchor" href="#Setting-Up-Qdrant" aria-label="Permalink to &quot;Setting Up Qdrant {#Setting-Up-Qdrant}&quot;">​</a></h3><p>Start Qdrant using Docker:</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">docker</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> run</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -p</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 6333:6333</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> qdrant/qdrant</span></span></code></pre></div><p>This runs Qdrant on the default port (<code>6333</code>). Kaimon connects to it automatically.</p><h3 id="Setting-Up-Ollama" tabindex="-1">Setting Up Ollama <a class="header-anchor" href="#Setting-Up-Ollama" aria-label="Permalink to &quot;Setting Up Ollama {#Setting-Up-Ollama}&quot;">​</a></h3><p>Install Ollama from <a href="https://ollama.com" target="_blank" rel="noreferrer">ollama.com</a>, then pull the default embedding model:</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ollama</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> pull</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> qwen3-embedding:0.6b</span></span></code></pre></div><p>The Search tab will show a health indicator for both services. If either is not running, the indicator turns red with an error message.</p><h2 id="Indexing-a-Project" tabindex="-1">Indexing a Project <a class="header-anchor" href="#Indexing-a-Project" aria-label="Permalink to &quot;Indexing a Project {#Indexing-a-Project}&quot;">​</a></h2><p>Before you can search, index the project. From the Search tab press <code>i</code>, or use the MCP tool directly:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>qdrant_index_project()</span></span>
<span class="line"><span>qdrant_index_project(project_path=&quot;/path/to/project&quot;)</span></span>
<span class="line"><span>qdrant_index_project(recreate=true)   # rebuild from scratch</span></span></code></pre></div><p>Indexing scans <code>.jl</code>, <code>.ts</code>, <code>.tsx</code>, <code>.jsx</code>, and <code>.md</code> files under the project&#39;s <code>src/</code>, <code>test/</code>, and <code>scripts/</code> directories. It splits them into chunks, computes embeddings, and stores everything in a Qdrant collection named after the project.</p><h3 id="auto-indexing" tabindex="-1">Auto-Indexing <a class="header-anchor" href="#auto-indexing" aria-label="Permalink to &quot;Auto-Indexing&quot;">​</a></h3><p>When a Julia REPL gate connects to Kaimon, the server automatically indexes its project in the background:</p><ul><li><p>If no collection exists yet, Kaimon detects the project type and runs a full index.</p></li><li><p>If a collection already exists, Kaimon runs an incremental sync to pick up any changed files.</p></li></ul><p>File-change notifications from the gate trigger incremental re-indexing automatically, with a 5-second debounce to batch rapid edits.</p><h2 id="The-Search-Tab" tabindex="-1">The Search Tab <a class="header-anchor" href="#The-Search-Tab" aria-label="Permalink to &quot;The Search Tab {#The-Search-Tab}&quot;">​</a></h2><p>Press <code>4</code> in the TUI to open the Search tab. It has three panes:</p><p><strong>Status pane</strong> (top) — shows Qdrant and Ollama health, the active collection, and the current embedding model.</p><p><strong>Query pane</strong> (middle) — type your search query here.</p><p><strong>Results pane</strong> (bottom) — scrollable list of matching code chunks with relevance scores.</p><h3 id="Running-a-Search" tabindex="-1">Running a Search <a class="header-anchor" href="#Running-a-Search" aria-label="Permalink to &quot;Running a Search {#Running-a-Search}&quot;">​</a></h3><ol><li><p>Press <code>/</code> to focus the query input.</p></li><li><p>Type your query in plain language.</p></li><li><p>Press <code>Enter</code> to run the search.</p></li><li><p>Use <code>Tab</code> to move focus to the results pane, then <code>↑</code>/<code>↓</code> to scroll.</p></li></ol><h3 id="Switching-Collections" tabindex="-1">Switching Collections <a class="header-anchor" href="#Switching-Collections" aria-label="Permalink to &quot;Switching Collections {#Switching-Collections}&quot;">​</a></h3><p>If you have multiple projects indexed, use <code>↑</code>/<code>↓</code> in the status pane to cycle through available collections. The active collection is highlighted.</p><h3 id="Filtering-by-Chunk-Type" tabindex="-1">Filtering by Chunk Type <a class="header-anchor" href="#Filtering-by-Chunk-Type" aria-label="Permalink to &quot;Filtering by Chunk Type {#Filtering-by-Chunk-Type}&quot;">​</a></h3><p>Press <code>d</code> to cycle through chunk type filters:</p><table tabindex="0"><thead><tr><th style="text-align:right;">Filter</th><th style="text-align:right;">What it returns</th></tr></thead><tbody><tr><td style="text-align:right;"><code>all</code> (default)</td><td style="text-align:right;">Both definition chunks and window chunks</td></tr><tr><td style="text-align:right;"><code>definitions</code></td><td style="text-align:right;">Only functions, structs, macros, and constants</td></tr><tr><td style="text-align:right;"><code>windows</code></td><td style="text-align:right;">Only sliding-window context chunks</td></tr></tbody></table><p>Use <code>definitions</code> when looking for a specific function or type. Use <code>windows</code> when you need broader context that spans multiple definitions.</p><h3 id="Key-Reference" tabindex="-1">Key Reference <a class="header-anchor" href="#Key-Reference" aria-label="Permalink to &quot;Key Reference {#Key-Reference}&quot;">​</a></h3><table tabindex="0"><thead><tr><th style="text-align:right;">Key</th><th style="text-align:right;">Action</th></tr></thead><tbody><tr><td style="text-align:right;"><code>/</code></td><td style="text-align:right;">Focus query input</td></tr><tr><td style="text-align:right;"><code>Enter</code></td><td style="text-align:right;">Submit query (when input focused)</td></tr><tr><td style="text-align:right;"><code>Tab</code></td><td style="text-align:right;">Cycle pane focus</td></tr><tr><td style="text-align:right;"><code>d</code></td><td style="text-align:right;">Cycle chunk type filter</td></tr><tr><td style="text-align:right;"><code>o</code></td><td style="text-align:right;">Open embedding model configuration</td></tr><tr><td style="text-align:right;"><code>m</code></td><td style="text-align:right;">Open collection manager</td></tr><tr><td style="text-align:right;"><code>r</code></td><td style="text-align:right;">Force-refresh service health</td></tr><tr><td style="text-align:right;"><code>p</code></td><td style="text-align:right;">Pull the active embedding model via Ollama</td></tr></tbody></table><h2 id="Embedding-Model-Configuration" tabindex="-1">Embedding Model Configuration <a class="header-anchor" href="#Embedding-Model-Configuration" aria-label="Permalink to &quot;Embedding Model Configuration {#Embedding-Model-Configuration}&quot;">​</a></h2><p>Press <code>o</code> to open the model configuration overlay. This shows all supported embedding models with their vector dimensions, context window size, and whether they are installed in Ollama.</p><table tabindex="0"><thead><tr><th style="text-align:right;">Model</th><th style="text-align:right;">Dimensions</th><th style="text-align:right;">Context</th><th style="text-align:right;">Notes</th></tr></thead><tbody><tr><td style="text-align:right;"><code>qwen3-embedding:0.6b</code></td><td style="text-align:right;">1024</td><td style="text-align:right;">8192 tokens</td><td style="text-align:right;">Default — fast, small</td></tr><tr><td style="text-align:right;"><code>qwen3-embedding:4b</code></td><td style="text-align:right;">2560</td><td style="text-align:right;">8192 tokens</td><td style="text-align:right;">Better quality, larger</td></tr><tr><td style="text-align:right;"><code>qwen3-embedding:8b</code></td><td style="text-align:right;">4096</td><td style="text-align:right;">8192 tokens</td><td style="text-align:right;">Highest quality</td></tr><tr><td style="text-align:right;"><code>qwen3-embedding</code> (latest)</td><td style="text-align:right;">4096</td><td style="text-align:right;">8192 tokens</td><td style="text-align:right;">Latest qwen3 release</td></tr><tr><td style="text-align:right;"><code>snowflake-arctic-embed</code></td><td style="text-align:right;">1024</td><td style="text-align:right;">512 tokens</td><td style="text-align:right;">Alternative model</td></tr><tr><td style="text-align:right;"><code>nomic-embed-text</code></td><td style="text-align:right;">768</td><td style="text-align:right;">512 tokens</td><td style="text-align:right;">Lightweight alternative</td></tr></tbody></table><h3 id="Switching-Models" tabindex="-1">Switching Models <a class="header-anchor" href="#Switching-Models" aria-label="Permalink to &quot;Switching Models {#Switching-Models}&quot;">​</a></h3><p>Press <code>o</code> from the Search tab to open the model configuration overlay:</p><p><img src="https://github.com/kahliburke/Kaimon.jl/releases/download/docs-assets/kaimon_search_config.gif" alt=""></p><p>Navigate with <code>↑</code>/<code>↓</code> and press <code>Enter</code> to select a model. Installed models are marked. If the new model has a different vector dimension than the current collection, Kaimon will warn you and prompt you to reindex (<code>y</code>/<code>n</code>). Press <code>y</code> to reindex all connected project collections with the new model.</p><p>Changing the embedding model requires reindexing — vectors from different models are not compatible. If you search and see a &quot;dimension mismatch&quot; error, press <code>o</code>, confirm the correct model is selected, and reindex.</p><h3 id="Installing-a-Model" tabindex="-1">Installing a Model <a class="header-anchor" href="#Installing-a-Model" aria-label="Permalink to &quot;Installing a Model {#Installing-a-Model}&quot;">​</a></h3><p>If a model shows as not installed, press <code>p</code> to pull it from Ollama. The pull runs in the background and the status updates when complete.</p><h2 id="Collection-Manager" tabindex="-1">Collection Manager <a class="header-anchor" href="#Collection-Manager" aria-label="Permalink to &quot;Collection Manager {#Collection-Manager}&quot;">​</a></h2><p>Press <code>m</code> to open the Collection Manager overlay. This shows all indexed projects with their status: vector count, stale file count (files changed since last index), and any active operations.</p><p>From the Collection Manager you can:</p><ul><li><p><strong>Reindex</strong> a collection — re-index all stale files in the background.</p></li><li><p><strong>Delete</strong> a collection — remove it from Qdrant entirely.</p></li><li><p><strong>Add an external project</strong> — index a project that is not currently connected as a gate session. Enter the project path, optionally adjust the source directories and file extensions, then confirm.</p></li></ul><h3 id="Stale-Files" tabindex="-1">Stale Files <a class="header-anchor" href="#Stale-Files" aria-label="Permalink to &quot;Stale Files {#Stale-Files}&quot;">​</a></h3><p>The stale count shows how many files have been modified since the last indexing run. A stale collection will return outdated results for changed code. Use reindex (from the Collection Manager or <code>qdrant_sync_index</code>) to bring it up to date.</p><h2 id="Collection-Management-Tools" tabindex="-1">Collection Management Tools <a class="header-anchor" href="#Collection-Management-Tools" aria-label="Permalink to &quot;Collection Management Tools {#Collection-Management-Tools}&quot;">​</a></h2><table tabindex="0"><thead><tr><th style="text-align:right;">Tool</th><th style="text-align:right;">Description</th></tr></thead><tbody><tr><td style="text-align:right;"><code>qdrant_index_project</code></td><td style="text-align:right;">Index or re-index a project. Use <code>recreate=true</code> to rebuild from scratch.</td></tr><tr><td style="text-align:right;"><code>qdrant_sync_index</code></td><td style="text-align:right;">Sync the index: re-index changed files, remove deleted ones.</td></tr><tr><td style="text-align:right;"><code>qdrant_reindex_file</code></td><td style="text-align:right;">Re-index a single file.</td></tr><tr><td style="text-align:right;"><code>qdrant_browse_collection</code></td><td style="text-align:right;">Browse indexed points with pagination.</td></tr><tr><td style="text-align:right;"><code>qdrant_collection_info</code></td><td style="text-align:right;">Get vector count, size, and configuration for a collection.</td></tr><tr><td style="text-align:right;"><code>qdrant_list_collections</code></td><td style="text-align:right;">List all available collections.</td></tr></tbody></table><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>qdrant_sync_index()</span></span>
<span class="line"><span>qdrant_sync_index(collection=&quot;MyProject&quot;)</span></span></code></pre></div>`,59)])])}const u=t(o,[["render",l]]);export{p as __pageData,u as default};
